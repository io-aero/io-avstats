{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Aviation Event Statistics","text":"<p>This repository is used for the development and maintenance of applications based on the data of the IO-AVSTATS database.  Currently, it includes the following applications:</p> <ul> <li><code>ae1982</code> - Aviation Event Analysis</li> <li><code>pd1982</code> - IO-AVSTATS-DB Database Profiling</li> <li><code>slara</code>\u00a0\u00a0 - Association Rule Analysis</li> <li><code>stats</code>\u00a0\u00a0 - US Aviation Fatal Accidents</li> </ul> <p>These applications and the database are available in the cloud via AWS. In addition, the maintenance of the database content is also done in this repository. </p> <p>The related database software is maintained in the repository io-avstats-db.</p>"},{"location":"LICENSE.html","title":"End-User License Agreement (EULA) of IO-Aero Software","text":"<p>This End-User License Agreement (\"EULA\") is a legal agreement between you and IO-Aero. </p> <p>This EULA agreement governs your acquisition and use of our IO-Aero Software (\"Software\") directly from IO-Aero or indirectly through a IO-Aero authorized reseller or distributor (a \"Reseller\").</p> <p>Please read this EULA agreement carefully before completing the installation process and using the IO-Aero Software.  It provides a license to use the IO-Aero Software and contains warranty information and liability disclaimers.</p> <p>If you register for a free trial of the IO-Aero Software, this EULA agreement will also govern that trial.  By clicking \"accept\" or installing and/or using the IO-Aero Software, you are confirming your acceptance of the Software and agreeing to become bound by the terms of this EULA agreement.</p> <p>If you are entering into this EULA agreement on behalf of a company or other legal entity, you represent that you have the authority to bind such entity and its affiliates to these terms and conditions.  If you do not have such authority or if you do not agree with the terms and conditions of this EULA agreement, do not install or use the Software, and you must not accept this EULA agreement.</p> <p>This EULA agreement shall apply only to the Software supplied by IO-Aero herewith regardless of whether other software is referred to or described herein.  The terms also apply to any IO-Aero updates, supplements, Internet-based services, and support services for the Software, unless other terms accompany those items on delivery.  If so, those terms apply.</p>"},{"location":"LICENSE.html#license-grant","title":"License Grant","text":"<p>IO-Aero hereby grants you a personal, non-transferable, non-exclusive licence to use the IO-Aero Software on your devices in accordance with the terms of this EULA agreement.</p> <p>You are permitted to load the IO-Aero Software (for example a PC, laptop, mobile or tablet) under your control.  You are responsible for ensuring your device meets the minimum requirements of the IO-Aero Software.</p>"},{"location":"LICENSE.html#you-are-not-permitted-to","title":"You are not permitted to:","text":"<ul> <li>Edit, alter, modify, adapt, translate or otherwise change the whole or any part of the Software nor permit the whole or any part of the Software to be combined with or become incorporated in any other software, nor decompile, disassemble or reverse engineer the Software or attempt to do any such things</li> <li>Reproduce, copy, distribute, resell or otherwise use the Software for any commercial purpose</li> <li>Allow any third party to use the Software on behalf of or for the benefit of any third party</li> <li>Use the Software in any way which breaches any applicable local, national or international law</li> <li>use the Software for any purpose that IO-Aero considers is a breach of this EULA agreement Intellectual Property and Ownership</li> </ul> <p>IO-Aero shall at all times retain ownership of the Software as originally downloaded by you and all subsequent downloads of the Software by you.  The Software (and the copyright, and other intellectual property rights of whatever nature in the Software, including any modifications made thereto) are and shall remain the property of IO-Aero.</p> <p>IO-Aero reserves the right to grant licences to use the Software to third parties.</p>"},{"location":"LICENSE.html#termination","title":"Termination","text":"<p>This EULA agreement is effective from the date you first use the Software and shall continue until terminated.  You may terminate it at any time upon written notice to IO-Aero.</p> <p>It will also terminate immediately if you fail to comply with any term of this EULA agreement.  Upon such termination, the licenses granted by this EULA agreement will immediately terminate, and you agree to stop all access and use of the Software.  The provisions that by their nature continue and survive will survive any termination of this EULA agreement.</p>"},{"location":"LICENSE.html#governing-law","title":"Governing Law","text":"<p>This EULA agreement, and any dispute arising out of or in connection with this EULA agreement, shall be governed by and construed in accordance with the laws of the United States.</p>"},{"location":"config_io_avstats.html","title":"Configuration - IO-AVSTATS","text":"<p>For the administration of the configuration parameters of IO-AVSTATS the tool dynaconf is used. The two files <code>settings.io_avstats.toml</code> and <code>.settings.io_avstats.toml</code> are available as configuration files. The <code>.settings.io_avstats.toml</code> file contains the security related parameters such as passwords and is not made available in the GitHub repository. The names of IO-AVSTATS related environment variables must include the prefix <code>IO_AVSTATS</code>. Layered environments are supported. The <code>test</code> layer is used for the automated tests.</p>"},{"location":"config_io_avstats.html#1-available-parameters","title":"1. Available Parameters","text":"Parameter Description correction_work_dir file directory containing the files with the manual corrections database_commit_size number of rows processed before a progress message is created download_chunk_size chunk size for download from the NTSB website download_file_aviation_occurrence_categories_xlsx name of the file containing data of aviation occurrence categories download_file_countries_states_json name of the file containing data of countries and states download_file_faa_airports_xlsx name of the file containing data of airports download_file_faa_npias_xlsx name of the file containing National Plan of Integrated Airport Systems download_file_faa_runways_xlsx name of the file containing data of runways download_file_main_phases_of_flight_xlsx name of the file containing data of main phases of a flight download_file_sequence_of_events_xlsx name of the file containing data of sequence of events download_file_simplemaps_us_cities_xlsx simplemaps: name of the zipped US city file download_file_simplemaps_us_zips_xlsx simplemaps: name of the zipped US zip code file download_file_zip_codes_org_xls ZIP Code Database: name of the unzipped US zip code file download_timeout seconds to wait for the server to send data download_url_ntsb_prefix prefix of the download link for the NTSB data sets download_work_dir working directory for the processing of NTSB data sets is_runtime_environment_local local execution environment - unlike Docker is_verbose display progress messages for processing max_deviation_latitude maximum decimal deviation of the latitude in the database table even max_deviation_longitude maximum decimal deviation of the longitude in the database table even odbc_connection_string connection string for the MS Access ODBC driver postgres_connection_port database port number postgres_container_name container name postgres_database_schema database schema name postgres_dbname database name postgres_dbname_admin administration database name postgres_host database server hostname postgres_password database password postgres_password_admin administration database password postgres_password_guest guest database password postgres_pgdata file directory on the host for the database files postgres_user database username postgres_user_admin administration database username postgres_user_guest guest database username postgres_version requested PostgreSQL version from DockerHub razorsql_jar_file_windows name of the jar file (Windows version) razorsql_java_path_windows name of the Java file (Windows version) razorsql_profile name of the RazorSQL connection profile razorsql_reference_dir file directory of the database schema reference file razorsql_reference_file file name of the database schema reference file"},{"location":"config_io_avstats.html#2-notes","title":"2. Notes","text":"<ol> <li>The configuration parameters <code>postgres_password</code> and <code>postgres_password_admin</code> can be found in the configuration file <code>.settings.io_avstats.toml</code>.</li> <li>The configuration parameters in the configuration files can be overridden with corresponding environment variables, e.g. the environment variable <code>IO_AVSTATS_IS_VERBOSE</code> overrides the configuration parameter <code>is_verbose</code>. </li> </ol>"},{"location":"config_logging.html","title":"Configuration - Logging","text":"<p>In IO-AVSTATS the Python standard module for logging is used - details can be found here.</p> <p>The file <code>logging_cfg.yaml</code> controls the logging behaviour of the application. </p>"},{"location":"config_logging.html#default-content","title":"Default content:","text":"<pre><code>version: 1\n\nformatters:\n  simple:\n    format: \"%(asctime)s [%(module)s.py  ] %(levelname)-5s %(funcName)s:%(lineno)d %(message)s\"\n  extended:\n    format: \"%(asctime)s [%(module)s.py  ] %(levelname)-5s %(funcName)s:%(lineno)d \\n%(message)s\"\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    level: INFO\n    formatter: simple\n\n  file_handler:\n    class: logging.FileHandler\n    level: INFO\n    filename: logging_io-avstats.log\n    formatter: extended\n\nloggers:\n  io-avstats:\n    handlers: [ console ]\nroot:\n  handlers: [ file_handler ]\n</code></pre>"},{"location":"how_to_add_ntsb_accident_files.html","title":"How to add NTSB accident files","text":"<p>Aviation accident data provided by NTSB can be found at the following website under 'Downloadable data sets':</p> <p></p> <p>NTSB provides the following files:</p> <ul> <li><code>Pre2008.zip</code>: data set for 1982 through 2007</li> <li><code>avall.zip</code>: data set from 2008 to the present </li> <li><code>upDDMON.zip</code>: monthly supplements on the 1st, 8th, 15th and 22nd</li> </ul> <p>In the database table <code>io_processed_files</code> you can find the files already processed by IO-AVSTATS:</p> <p></p> <p>Any file provided by NTSB can be processed several times with the process described in the following, as long as one processes also afterward all newer files again.</p>"},{"location":"how_to_add_ntsb_accident_files.html#1-to-do-list","title":"1. To-Do List","text":"<p>All processing taskss in 1.1, 1.2 and 1.3 can be executed with the <code>run_io_avstats</code> script. For a more detailed description of these tasks, see under Operation.</p>"},{"location":"how_to_add_ntsb_accident_files.html#11-modified-non-ntsb-data-sources","title":"1.1 Modified Non-NTSB data sources","text":"<p>The following steps are performed only if the source files have changed:</p> Task Description l_a_p Load airport data into PostgreSQL a_o_c Load aviation occurrence categories into PostgreSQL l_c_s Load country and state data into PostgreSQL l_s_e Load sequence of events data into PostgreSQL l_s_d Load simplemaps data into PostgreSQL l_z_d Load ZIP Code Database data into PostgreSQL"},{"location":"how_to_add_ntsb_accident_files.html#12-ntsb-file-avallzip","title":"1.2 NTSB file <code>avall.zip</code>","text":"<p>The following task must be performed on the first of each month:</p> Task Description l_n_a Load NTSB MS Access database data into PostgreSQL <ul> <li>Stop the Docker container <code>io_avstats_db</code>.</li> <li>Remove the directory <code>data/postgres</code></li> <li>Unzip the latest file <code>yy.mm.dd_postgres_Pre2008_20.09.30.zip</code></li> <li>Start the Docker container <code>io_avstats_db</code></li> <li>Run script <code>run_io_avstats</code> with task <code>l_n_a</code> and file <code>avall</code></li> </ul>"},{"location":"how_to_add_ntsb_accident_files.html#13-ntsb-file-upddmonzip","title":"1.3 NTSB file <code>upDDMON.zip</code>","text":"<p>The following tasks must be performed every month on the 1st, 8th, 15th and 22nd:</p> No. Task Description either u_p_d Download a NTSB MS Access database file or  1. l_n_a Load NTSB MS Access database data into PostgreSQL 2. l_c_d optional Load data from a correction file into PostgreSQL 3. c_l_l Correct decimal US latitudes and longitudes 4. f_n_a Find the nearest airports 5. v_n_d Verify selected NTSB data 6. r_d_s Refresh the PostgreSQL database schema"},{"location":"how_to_add_ntsb_accident_files.html#14-backup","title":"1.4 Backup","text":"<p>The following steps are used to backup the database IO-AVSTATS-DB:</p> No. Task Description 1. Backup the file directory <code>data/postgres</code> 2. Update the Google Drive"},{"location":"how_to_add_ntsb_accident_files.html#2-a-few-tips","title":"2. A few tips","text":""},{"location":"how_to_add_ntsb_accident_files.html#21-backup-the-file-directory-datapostgres","title":"2.1 Backup the file directory <code>data/postgres</code>","text":"<ul> <li>Stop the Docker container <code>io_avstats_db</code>.</li> <li>Zip the file directory <code>postgres</code> in the file directory <code>data</code> - result is the file <code>postgres.zip</code>.</li> <li>Rename the file <code>postgres.sql</code> to <code>yy.mm.dd_postgres_upDDMON.zip</code>.</li> <li>Create a copy of the file <code>yy.mm.dd_postgres_upDDMON.zip</code> with the name <code>latest_postgres.zip</code>.</li> </ul>"},{"location":"how_to_add_ntsb_accident_files.html#22-update-the-google-drive","title":"2.2 Update the Google Drive","text":"<ul> <li>Log in to Google Drive with the Google Account <code>io-avstats.io-aero@gmail.com</code>.</li> <li>Upload the file <code>yy.mm.dd_postgres_upDDMON.zip</code>.</li> <li>Share the newly uploaded file.</li> </ul>"},{"location":"how_to_add_ntsb_accident_files.html#23-optional-data-quality-checks","title":"2.3 Optional data quality checks","text":""},{"location":"how_to_add_ntsb_accident_files.html#231-event-completeness","title":"2.3.1 Event completeness","text":"<p>Query:</p> <pre><code>SELECT count(*) \"Count\",\n       'Events Total' \"Description\"\n  FROM events e\n UNION\nSELECT count(*) ,\n       'Events Total with Fatalities'\n  FROM events e\n WHERE inj_tot_f &gt; 0\n UNION\nSELECT count(*) ,\n       'Events US'\n  FROM events e\n WHERE ev_state IS NOT NULL\n   AND ev_state IN (SELECT state\n                      FROM io_states is2)\n UNION\nSELECT count(*) ,\n       'Events US with Fatalities'\n  FROM events e\n WHERE inj_tot_f &gt; 0\n   AND ev_state IS NOT NULL\n   AND ev_state IN (SELECT state\n                      FROM io_states is2)\n UNION\nSELECT count(*) \"Count\",\n       'Events Total since 1982' \"Description\"\n  FROM events e\n WHERE ev_year &gt;= 1982\n UNION\nSELECT count(*) ,\n       'Events Total with Fatalities since 1982'\n  FROM events e\n WHERE ev_year &gt;= 1982\n   AND inj_tot_f &gt; 0\n UNION\nSELECT count(*) ,\n       'Events US since 1982'\n  FROM events e\n WHERE ev_year &gt;= 1982\n   AND ev_state IS NOT NULL\n   AND ev_state IN (SELECT state\n                      FROM io_states is2)\n UNION\nSELECT count(*) ,\n       'Events US with Fatalities since 1982'\n  FROM events e\n WHERE ev_year &gt;= 1982\n   AND inj_tot_f &gt; 0\n   AND ev_state IS NOT NULL\n   AND ev_state IN (SELECT state\n                      FROM io_states is2)\n UNION\nSELECT count(*) \"Count\",\n       'Events Total since 2008' \"Description\"\n  FROM events e\n WHERE ev_year &gt;= 2008\n UNION\nSELECT count(*) ,\n       'Events Total with Fatalities since 2008'\n  FROM events e\n WHERE ev_year &gt;= 2008\n   AND inj_tot_f &gt; 0\n UNION\nSELECT count(*) ,\n       'Events US since 2008'\n  FROM events e\n WHERE ev_year &gt;= 2008\n   AND ev_state IS NOT NULL\n   AND ev_state IN (SELECT state\n                      FROM io_states is2)\n UNION\nSELECT count(*) ,\n       'Events US with Fatalities since 2008'\n  FROM events e\n WHERE ev_year &gt;= 2008\n   AND inj_tot_f &gt; 0\n   AND ev_state IS NOT NULL\n   AND ev_state IN (SELECT state\n                      FROM io_states is2)\n ORDER BY 2\n</code></pre>"},{"location":"how_to_add_ntsb_accident_files.html#232-latitude-longitude","title":"2.3.2 Latitude &amp; longitude","text":"<p>Query Total::</p> <pre><code>SELECT count(*) \"Count\",\n       io_dec_lat_lng_actions\n  FROM events \n WHERE io_dec_lat_lng_actions IS NOT NULL \n GROUP BY io_dec_lat_lng_actions \n ORDER BY io_dec_lat_lng_actions\n</code></pre> <p>Query Total since 1982::</p> <pre><code>SELECT count(*) \"Count\",\n       io_dec_lat_lng_actions\n  FROM events \n WHERE ev_year &gt;= 1982\n   AND io_dec_lat_lng_actions IS NOT NULL \n GROUP BY io_dec_lat_lng_actions \n ORDER BY io_dec_lat_lng_actions\n</code></pre> <p>Query Total since 2008::</p> <pre><code>SELECT count(*) \"Count\",\n       io_dec_lat_lng_actions\n  FROM events \n WHERE ev_year &gt;= 2008\n   AND io_dec_lat_lng_actions IS NOT NULL \n GROUP BY io_dec_lat_lng_actions \n ORDER BY io_dec_lat_lng_actions\n</code></pre>"},{"location":"how_to_add_ntsb_accident_files.html#233-issue-summary","title":"2.3.3 Issue summary","text":"<p>Query Total::</p> <pre><code>SELECT count(*) \"Count\",\n       'Latitude deviation' \"Description\"\n  FROM events e\n WHERE io_dec_latitude_deviating IS NOT NULL \n UNION\nSELECT count(*),\n       'Longitude deviation'\n  FROM events e\n WHERE io_dec_longitude_deviating IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid Latitude'\n  FROM events e\n WHERE io_invalid_latitude IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid Longitude'\n  FROM events e\n WHERE io_invalid_longitude IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US City'\n  FROM events e\n WHERE io_invalid_us_city IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US City &amp; Zipcode'\n  FROM events e\n WHERE io_invalid_us_city_zipcode IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US State'\n  FROM events e\n WHERE io_invalid_us_state IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US Zipcode'\n  FROM events e\n WHERE io_invalid_us_zipcode IS NOT NULL \n ORDER BY 2\n</code></pre> <p>Query US until 2008::</p> <pre><code>SELECT count(*) \"Count\",\n       'Latitude deviation' \"Description\"\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_dec_latitude_deviating IS NOT NULL \n UNION\nSELECT count(*),\n       'Longitude deviation'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_dec_longitude_deviating IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid Latitude'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_invalid_latitude IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid Longitude'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_invalid_longitude IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US City'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_invalid_us_city IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US City &amp; Zipcode'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_invalid_us_city_zipcode IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US State'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_invalid_us_state IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US Zipcode'\n  FROM events e\n WHERE ev_year &lt; 2008 \n   AND io_invalid_us_zipcode IS NOT NULL \n ORDER BY 2\n</code></pre> <p>Query US Accidents since 2008::</p> <pre><code>SELECT count(*) \"Count\",\n       'Latitude deviation' \"Description\"\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_dec_latitude_deviating IS NOT NULL \n UNION\nSELECT count(*),\n       'Longitude deviation'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_dec_longitude_deviating IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid Latitude'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_invalid_latitude IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid Longitude'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_invalid_longitude IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US City'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_invalid_us_city IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US City &amp; Zipcode'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_invalid_us_city_zipcode IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US State'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_invalid_us_state IS NOT NULL \n UNION\nSELECT count(*) ,\n       'Invalid US Zipcode'\n  FROM events e\n WHERE ev_year &gt;= 2008 \n   AND io_invalid_us_zipcode IS NOT NULL \n ORDER BY 2\n</code></pre>"},{"location":"how_to_compare_ntsb_and_io_db.html","title":"How to compare NTSB and IO-AVSTATS-DB","text":""},{"location":"how_to_compare_ntsb_and_io_db.html#1-general","title":"1. General","text":"<p>The reconciliation of the databases of IO-Aero and NTSB can always be done only at the first of the month, because the NTSB updates the database avall only at this time. The MS Excel file data\\Database Matching\\database_matching.xlsx is used for reconciliation.</p>"},{"location":"how_to_compare_ntsb_and_io_db.html#2-io-avstats-db","title":"2. IO-AVSTATS-DB","text":"<p>The reconciliation data from the IO-Aero Database IO-AVSTATS-DB is determined with the following database query:</p> <pre><code>SELECT 'aircraft'                                                                                      \"DB Table\",\n(SELECT count(*) FROM aircraft WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM aircraft WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM aircraft)                                                                 \"Total\"\nUNION\nSELECT 'dt_aircraft'                                                                                      \"DB Table\",\n(SELECT count(*) FROM dt_aircraft WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM dt_aircraft WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM dt_aircraft)                                                                 \"Total\"\nUNION\nSELECT 'dt_events'                                                                                      \"DB Table\",\n(SELECT count(*) FROM dt_events WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM dt_events WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM dt_events)                                                                 \"Total\"\nUNION\nSELECT 'dt_flight_crew'                                                                                      \"DB Table\",\n(SELECT count(*) FROM dt_flight_crew WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM dt_flight_crew WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM dt_flight_crew)                                                                 \"Total\"\nUNION\nSELECT 'engines'                                                                                      \"DB Table\",\n(SELECT count(*) FROM engines WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM engines WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM engines)                                                                 \"Total\"\nUNION\nSELECT 'events'                                            \"DB Table\",\n(SELECT count(*) FROM events WHERE ev_year &lt; 2008)  \"&lt; 2008\",\n(SELECT count(*) FROM events WHERE ev_year &gt;= 2008) \"&gt;= 2008\",\n(SELECT count(*) FROM events)                       \"Total\"\nunion\nSELECT 'events_sequence'                                                                                      \"DB Table\",\n(SELECT count(*) FROM events_sequence WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM events_sequence WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM events_sequence)                                                                 \"Total\"\nunion\nSELECT 'findings'                                                                                      \"DB Table\",\n(SELECT count(*) FROM findings WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM findings WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM findings)                                                                 \"Total\"\nunion\nSELECT 'flight_crew'                                                                                      \"DB Table\",\n(SELECT count(*) FROM flight_crew WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM flight_crew WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM flight_crew)                                                                 \"Total\"\nunion\nSELECT 'flight_time'                                                                                      \"DB Table\",\n(SELECT count(*) FROM flight_time WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM flight_time WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM flight_time)                                                                 \"Total\"\nunion\nSELECT 'injury'                                                                                      \"DB Table\",\n(SELECT count(*) FROM injury WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM injury WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM injury)                                                                 \"Total\"\nunion\nSELECT 'narratives'                                                                                      \"DB Table\",\n(SELECT count(*) FROM narratives WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM narratives WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM narratives)                                                                 \"Total\"\nunion\nSELECT 'ntsb_admin'                                                                                      \"DB Table\",\n(SELECT count(*) FROM ntsb_admin WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM ntsb_admin WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM ntsb_admin)                                                                 \"Total\"\nunion\nSELECT 'occurrences'                                                                                      \"DB Table\",\n(SELECT count(*) FROM occurrences WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM occurrences WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM occurrences)                                                                 \"Total\"\nunion\nSELECT 'seq_of_events'                                                                                      \"DB Table\",\n(SELECT count(*) FROM seq_of_events WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &lt; 2008))  \"&lt; 2008\",\n(SELECT count(*) FROM seq_of_events WHERE ev_id IN (SELECT ev_id FROM events WHERE ev_year &gt;= 2008)) \"&gt;= 2008\",\n(SELECT count(*) FROM seq_of_events)                                                                 \"Total\"\nORDER BY 1\n</code></pre>"},{"location":"how_to_compare_ntsb_and_io_db.html#3-ntsb","title":"3. NTSB","text":"<p>To do this, these databases must first be downloaded from the NTSB website with task d_n_a. </p> <p>The reconciliation data of both NTSB databases Pre2008 and avall are determined with the following database query:</p> <pre><code>SELECT 'aircraft' AS db_table,\ncount(*)   AS total\nFROM aircraft\nUNION\nSELECT 'dt_aircraft' AS db_table,\ncount(*)      AS total\nFROM dt_aircraft\nUNION\nSELECT 'dt_events' AS db_table,\ncount(*)    AS total\nFROM dt_events\nUNION\nSELECT 'dt_flight_crew' AS db_table,\ncount(*)         AS total\nFROM dt_flight_crew\nUNION\nSELECT 'engines' AS db_table,\ncount(*)  AS total\nFROM engines\nUNION\nSELECT 'events' AS db_table,\ncount(*) AS total\nFROM events\nUNION\nSELECT 'events_sequence' AS db_table,\ncount(*)          AS total\nFROM events_sequence\nUNION\nSELECT 'findings' AS db_table,\ncount(*)   AS total\nFROM findings\nUNION\nSELECT 'flight_crew' AS db_table,\ncount(*)      AS total\nFROM flight_crew\nUNION\nSELECT 'flight_time' AS db_table,\ncount(*)      AS total\nFROM flight_time\nUNION\nSELECT 'injury' AS db_table,\ncount(*) AS total\nFROM injury\nUNION\nSELECT 'narratives' AS db_table,\ncount(*)     AS total\nFROM narratives\nUNION\nSELECT 'ntsb_admin' AS db_table,\ncount(*)     AS total\nFROM ntsb_admin\nUNION\nSELECT 'occurrences' AS db_table,\ncount(*)      AS total\nFROM occurrences\nUNION\nSELECT 'seq_of_events' AS db_table,\ncount(*)        AS total\nFROM seq_of_events\nORDER BY 1\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html","title":"How to create a new Streamlit app checklist","text":""},{"location":"how_to_create_new_streamlit_app.html#1-naming-conventions","title":"1. Naming Conventions","text":"Identification Header ae1982 Aircraft Accidents in the US since 1982 pd1982 Profiling Data for the US since 1982"},{"location":"how_to_create_new_streamlit_app.html#2-coding","title":"2. Coding","text":"<p>Adherence to the following recommendations will ensure consistent usability across all of IO-Aero's Streamlit applications:</p> <ul> <li>Use the sidebar for task and filter related controls</li> <li>Position the task-related controls in the sidebar at the top and the global filter elements at the bottom</li> <li>Make the task-related control elements visible only after the associated task has been selected</li> </ul> <pre><code>choice_data_profile = st.sidebar.checkbox(\n    help=\"Pandas profiling of the dataset.\",\n    label=\"**`Show data profile`**\",\n    value=False,\n)\n\nif choice_data_profile:\n    choice_data_profile_type = st.sidebar.radio(\n        help=\"explorative: thorough but also slow - minimal: minimal but faster.\",\n        index=1,\n        label=\"Data profile type\",\n        options=(\n            [\n                \"explorative\",\n                \"minimal\",\n            ]\n        ),\n    )\n    choice_data_profile_file = st.sidebar.checkbox(\n        help=\"Export the Pandas profile into a file.\",\n        label=\"Export profile to file\",\n        value=False,\n    )\n</code></pre> <ul> <li>Separate the individual tasks and the filter elements with separator line</li> </ul> <pre><code>st.sidebar.markdown(\"\"\"---\"\"\")\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#3-documentation","title":"3. Documentation","text":"<p>see file directory <code>docs</code></p>"},{"location":"how_to_create_new_streamlit_app.html#31-how_to_update_avstats_on_awsmd","title":"3.1 how_to_update_avstats_on_aws.md","text":"<pre><code>## 1. Docker images\n\nCurrently, the following Streamlit applications are supported:\n\n| Application | Description                             |\n|-------------|-----------------------------------------|\n| ae1982      | Aircraft Accidents in the US since 1982 |\n| pd1982      | Profiling Data for the US since 1982    |\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#32-indexmd","title":"3.2 index.md","text":"<pre><code>Currently, it includes the following applications:\n\n- ae1982 - Aircraft Accidents in the US since 1982\n- pd1982 - Profiling Data for the US since 1982\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#33-operationmd","title":"3.3 Operation.md","text":"<pre><code>TODO\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#4-parameterization","title":"4. Parameterization","text":""},{"location":"how_to_create_new_streamlit_app.html#41-docker-composeyml","title":"4.1 docker-compose.yml","text":"<pre><code>  # ------------------------------------------------------------------------------\n  # ae1982 - Aircraft Accidents in the US since 1982.\n  # ------------------------------------------------------------------------------\n  app_ae1982:\n    container_name: ae1982\n    depends_on:\n      - db\n    image: ioaero/ae1982:latest\n    ports:\n      - \"${IO_AVSTATS_STREAMLIT_SERVER_PORT_AE1982}:${IO_AVSTATS_STREAMLIT_SERVER_PORT}\"\n    restart: always\n\n  # ------------------------------------------------------------------------------\n  # pd1982 - Profiling Data for the US since 1982.\n  # ------------------------------------------------------------------------------\n  app_pd1982:\n    container_name: pd1982\n    depends_on:\n      - db\n    image: ioaero/pd1982:latest\n    ports:\n      - \"${IO_AVSTATS_STREAMLIT_SERVER_PORT_PD1982}:${IO_AVSTATS_STREAMLIT_SERVER_PORT}\"\n    restart: always\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#5-scripts","title":"5. Scripts","text":""},{"location":"how_to_create_new_streamlit_app.html#51-run_io_avstats","title":"5.1 run_io_avstats","text":"<p>cmd:</p> <pre><code>if [\"%IO_AVSTATS_TASK%\"] EQU [\"r_s_a\"] (\n    if [\"%2\"] EQU [\"\"] (\n        echo =========================================================\n        echo ae1982 - Aircraft Accidents in the US since 1982\n        echo pd1982 - Profiling Data for the US since 1982\n        echo ---------------------------------------------------------\n        set /P IO_AVSTATS_APPLICATION=\"Enter the Streamlit application name \"\n    ) else (\n        set IO_AVSTATS_APPLICATION=%2\n    )\n)\n</code></pre> <p>bash:</p> <pre><code>if [ \"${IO_AVSTATS_TASK}\" = \"r_s_a\" ]; then\n    if [ -z \"$2\" ]; then\n        echo \"=========================================================\"\n        echo \"ae1982 - Aircraft Accidents in the US since 1982\"\n        echo \"pd1982 - Profiling Data for the US since 1982\"\n        echo \"---------------------------------------------------------\"\n        # shellcheck disable=SC2162\n        read -p \"Enter the Streamlit application name \" IO_AVSTATS_APPLICATION\n        export IO_AVSTATS_APPLICATION=${IO_AVSTATS_APPLICATION}\n    else\n        export IO_AVSTATS_APPLICATION=$2\n    fi\nfi\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#52-see-file-directory-scripts","title":"5.2 See file directory <code>scripts</code>","text":""},{"location":"how_to_create_new_streamlit_app.html#521-scriptsrun_create_image","title":"5.2.1 scripts/run_create_image","text":"<p>cmd:</p> <pre><code>if [\"%1\"] EQU [\"\"] (\n    echo =========================================================\n    echo ae1982 - Aircraft Accidents in the US since 1982\n    echo pd1982 - Profiling Data for the US since 1982\n    echo ---------------------------------------------------------\n    set /P APPLICATION=\"Enter the desired application name [default: %APPLICATION_DEFAULT%] \"\n\n    if [\"!APPLICATION!\"] EQU [\"\"] (\n        set APPLICATION=%APPLICATION_DEFAULT%\n    )\n) else (\n    set APPLICATION=%1\n)\n</code></pre> <p>bash:</p> <pre><code>if [ -z \"$1\" ]; then\n    echo \"=========================================================\"\n    echo \"ae1982 - Aircraft Accidents in the US since 1982\"\n    echo \"pd1982 - Profiling Data for the US since 1982\"\n    echo \"---------------------------------------------------------\"\n    read -p \"Enter the desired application name [default: ${APPLICATION_DEFAULT}] \" APPLICATION\n    export APPLICATION=${APPLICATION}\n\n    if [ -z \"${APPLICATION}\" ]; then\n        export APPLICATION=${APPLICATION_DEFAULT}\n    fi\nelse\n    export APPLICATION=$1\nfi\n</code></pre>"},{"location":"how_to_create_new_streamlit_app.html#522-scriptsrun_docker_compose","title":"5.2.2 scripts/run_docker_compose","text":"<p>cmd:</p> <pre><code>set IO_AVSTATS_STREAMLIT_SERVER_PORT_X...X=99999\n...\necho STREAMLIT_SRRVER_PORT_X...X : %IO_AVSTATS_STREAMLIT_SERVER_PORT_X...X%\n</code></pre> <p>bash:</p> <pre><code>export IO_AVSTATS_STREAMLIT_SERVER_PORT_X...X=99999\n...\necho \"STREAMLIT_SRRVER_PORT_X...X : ${IO_AVSTATS_STREAMLIT_SERVER_PORT_X...X}\"\n</code></pre>"},{"location":"how_to_setup_aws_instance.html","title":"How to set up an AWS instance","text":"<p>Creating an AWS instance requires access to an AWS account as a root user or as an IAM user with appropriate permissions.</p> <p>IO-AVSTATS can be run on EC2 instances by default.  The EC2 instances are managed on the EC2 Dashboard.</p> <p></p>"},{"location":"how_to_setup_aws_instance.html#1-instance-creation","title":"1. Instance creation","text":"<p>On the EC2 dashboard, select Instances and then Launch instance.</p> <p></p>"},{"location":"how_to_setup_aws_instance.html#11-name-and-tags","title":"1.1 Name and tags","text":"<ul> <li><code>IO-AVSTATS</code></li> </ul>"},{"location":"how_to_setup_aws_instance.html#12-application-and-os-images","title":"1.2 Application and OS Images","text":"<ul> <li><code>Ubuntu Server 20.04 LTS (HVM), SSD Volume Type</code></li> </ul>"},{"location":"how_to_setup_aws_instance.html#13-instance-type","title":"1.3 Instance type","text":"<ul> <li><code>t3a.medium</code></li> </ul>"},{"location":"how_to_setup_aws_instance.html#14-key-pair-login","title":"1.4 Key pair (login)","text":"<ul> <li>Either choose an existing one or create a new one.</li> </ul>"},{"location":"how_to_setup_aws_instance.html#15-network-settings","title":"1.5 Network settings","text":""},{"location":"how_to_setup_aws_instance.html#16-configure-storage","title":"1.6 Configure Storage","text":"<ul> <li>1x <code>30</code> GiB</li> </ul>"},{"location":"how_to_setup_aws_instance.html#17-launch-instance","title":"1.7 Launch instance","text":""},{"location":"how_to_setup_aws_instance.html#2-open-port-numbers","title":"2. Open port numbers","text":"<p>Each Streamlit application must be assigned its own port number so that they can run simultaneously. Currently, the following Streamlit applications are supported:</p> Application ae1982 - Aviation Events since since 1982 pd1982 - Profiling Data since 1982 slara  - Association Rule Analysis stats  - Aviation Events since since 1982 - Limited Version"},{"location":"how_to_setup_aws_instance.html#21-determine-the-security","title":"2.1 Determine the security","text":"<p>To determine the security group assigned to the intance: on the EC2 dashboard, select Instances and then Security.</p> <p></p>"},{"location":"how_to_setup_aws_instance.html#22-choose-the-security-group","title":"2.2 Choose the security group","text":"<p>To choose the security group assigned to the instance: on the EC2 dashboard, select Security Groups and Security.</p> <p></p>"},{"location":"how_to_setup_aws_instance.html#23-open-the-port-numbers","title":"2.3 Open the port numbers","text":"<p>For each streamline application port number press <code>Add rule</code> and enter the data.</p> <p></p>"},{"location":"how_to_setup_aws_instance.html#24-finsh-with-save-rules","title":"2.4 Finsh with <code>Save rules</code>","text":""},{"location":"how_to_setup_aws_instance.html#3-upload-installation-script","title":"3. Upload installation script","text":"<p>On Windows, the WinSCP program can be used to upload data from the local system to the AWS Cloud. The script to be uploaded is called <code>run_cloud_setup_instance.sh</code>.</p> <p></p> <p></p>"},{"location":"how_to_setup_aws_instance.html#4-run-installation-script","title":"4. Run installation script","text":""},{"location":"how_to_setup_aws_instance.html#41-load-terminal-window","title":"4.1 Load terminal window","text":""},{"location":"how_to_setup_aws_instance.html#42-run_cloud_setup_instance","title":"4.2 <code>run_cloud_setup_instance</code>","text":"<p><code>chmod +x run_cloud_setup_instance.sh</code> </p> <p><code>./run_cloud_setup_instance.sh</code> </p> <p>Example protocol:</p> <pre><code>ubuntu@ip-172-31-89-93:~$ chmod +x run_cloud_setup_instance.sh\nubuntu@ip-172-31-89-93:~$ ./run_cloud_setup_instance.sh\n==============================================================================\nStart ./run_cloud_setup_instance.sh\n------------------------------------------------------------------------------\nDATE TIME : 19.12.2022 10:49:15\n==============================================================================\nSupplement necessary system software\n------------------------------------------------------------------------------\nHit:1 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal InRelease\nGet:2 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\nGet:3 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\nGet:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\nGet:5 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal/universe amd64 Packages [8628 kB]\nGet:6 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal/universe Translation-en [5124 kB]\nGet:7 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal/universe amd64 c-n-f Metadata [265 kB]\nGet:8 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [144 kB]\nGet:9 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal/multiverse Translation-en [104 kB]\nGet:10 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal/multiverse amd64 c-n-f Metadata [9136 B]\nGet:11 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2269 kB]\nGet:12 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/main Translation-en [395 kB]\nGet:13 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/main amd64 c-n-f Metadata [16.1 kB]\nGet:14 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1476 kB]\nGet:15 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/restricted Translation-en [208 kB]\nGet:16 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/restricted amd64 c-n-f Metadata [592 B]\nGet:17 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1009 kB]\nGet:18 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/universe Translation-en [234 kB]\nGet:19 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/universe amd64 c-n-f Metadata [23.2 kB]\nGet:20 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [24.5 kB]\nGet:21 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/multiverse Translation-en [7380 B]\nGet:22 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 c-n-f Metadata [592 B]\nGet:23 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [45.7 kB]\nGet:24 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/main Translation-en [16.3 kB]\nGet:25 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/main amd64 c-n-f Metadata [1420 B]\nGet:26 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/restricted amd64 c-n-f Metadata [116 B]\nGet:27 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [24.9 kB]\nGet:28 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/universe Translation-en [16.3 kB]\nGet:29 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/universe amd64 c-n-f Metadata [880 B]\nGet:30 http://us-east-1.ec2.archive.ubuntu.com/ubuntu focal-backports/multiverse amd64 c-n-f Metadata [116 B]\nGet:31 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [1895 kB]\nGet:32 http://security.ubuntu.com/ubuntu focal-security/main Translation-en [311 kB]\nGet:33 http://security.ubuntu.com/ubuntu focal-security/main amd64 c-n-f Metadata [11.5 kB]\nGet:34 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1385 kB]\nGet:35 http://security.ubuntu.com/ubuntu focal-security/restricted Translation-en [195 kB]\nGet:36 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 c-n-f Metadata [596 B]\nGet:37 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [778 kB]\nGet:38 http://security.ubuntu.com/ubuntu focal-security/universe Translation-en [150 kB]\nGet:39 http://security.ubuntu.com/ubuntu focal-security/universe amd64 c-n-f Metadata [16.8 kB]\nGet:40 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [22.2 kB]\nGet:41 http://security.ubuntu.com/ubuntu focal-security/multiverse Translation-en [5464 B]\nGet:42 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 c-n-f Metadata [516 B]\nFetched 25.2 MB in 4s (5617 kB/s)\nReading package lists...\n\n...\n\n=============================================================================&gt; Version  Docker Compose:\n\nCurrent version of Docker Compose: docker-compose version 1.25.0, build unknown\ndocker-py version: 4.1.0\nCPython version: 3.8.10\nOpenSSL version: OpenSSL 1.1.1f  31 Mar 2020\n\n==============================================================================\n\n=============================================================================&gt; Version  Docker Desktop:\n\nCurrent version of Docker Desktop: Client: Docker Engine - Community\n Version:           20.10.22\n API version:       1.41\n Go version:        go1.18.9\n Git commit:        3a2c30b\n Built:             Thu Dec 15 22:28:08 2022\n OS/Arch:           linux/amd64\n Context:           default\n Experimental:      true\n\nServer: Docker Engine - Community\n Engine:\n  Version:          20.10.22\n  API version:      1.41 (minimum version 1.12)\n  Go version:       go1.18.9\n  Git commit:       42c8b31\n  Built:            Thu Dec 15 22:25:58 2022\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          1.6.13\n  GitCommit:        78f51771157abb6c9ed224c22013cdf09962315d\n runc:\n  Version:          1.1.4\n  GitCommit:        v1.1.4-0-g5fd4c4d\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n\n==============================================================================\n\n=============================================================================&gt; Version  dos2unix:\n\nCurrent version of dos2unix: dos2unix 7.4.0 (2017-10-10)\nWith Unicode UTF-16 support.\nWith native language support.\nWith support to preserve the user and group ownership of files.\nLOCALEDIR: /usr/share/locale\nhttp://waterlan.home.xs4all.nl/dos2unix.html\n\n==============================================================================\n\n=============================================================================&gt; Version  unzip:\n\nCurrent version of unzip: UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n\nLatest sources and executables are at ftp://ftp.info-zip.org/pub/infozip/ ;\nsee ftp://ftp.info-zip.org/pub/infozip/UnZip.html for other sites.\n\nCompiled with gcc 9.4.0 for Unix (Linux ELF).\n\nUnZip special compilation options:\n        ACORN_FTYPE_NFS\n        COPYRIGHT_CLEAN (PKZIP 0.9x unreducing method not supported)\n        SET_DIR_ATTRIB\n        SYMLINKS (symbolic links supported, if RTL and file system permit)\n        TIMESTAMP\n        UNIXBACKUP\n        USE_EF_UT_TIME\n        USE_UNSHRINK (PKZIP/Zip 1.x unshrinking method supported)\n        USE_DEFLATE64 (PKZIP 4.x Deflate64(tm) supported)\n        UNICODE_SUPPORT [wide-chars, char coding: UTF-8] (handle UTF-8 paths)\n        LARGE_FILE_SUPPORT (large files over 2 GiB supported)\n        ZIP64_SUPPORT (archives using Zip64 for large files supported)\n        USE_BZIP2 (PKZIP 4.6+, using bzip2 lib version 1.0.8, 13-Jul-2019)\n        VMS_TEXT_CONV\n        WILD_STOP_AT_DIR\n        [decryption, version 2.11 of 05 Jan 2007]\n\nUnZip and ZipInfo environment options:\n           UNZIP:  [none]\n        UNZIPOPT:  [none]\n         ZIPINFO:  [none]\n      ZIPINFOOPT:  [none]\n\n==============================================================================\n\n--------------------------------------------------------------------------------\nDATE TIME : 19.12.2022 10:50:52\n--------------------------------------------------------------------------------\nEnd   ./run_cloud_setup_instance.sh\n================================================================================\n</code></pre>"},{"location":"how_to_update_avstats_on_aws.html","title":"How to update IO-AVSTATS in an AWS instance","text":"<p>The cloud version of IO-AVSTATS consists of a series of docker containers that are launched using Docker Compose. For the PostgreSQL database, the official DockerHub image from here is used. A separate Docker image is created for each of the Streamlit applications. </p>"},{"location":"how_to_update_avstats_on_aws.html#1-docker-images","title":"1. Docker images","text":"<p>Currently, the following Streamlit applications are supported:</p> Application Description all All Streamlit applications ae1982 Aircraft Accidents in the US since 1982 pd1982 Profiling Data for the US since 1982 <p>The script <code>run_io_avstats</code> with task <code>c_d_i</code> can be used to create or update the necessary Docker images.</p> <p>Example protocol:</p> <pre><code>...&gt;run_io_avstats\n=========================================================\nr_s_a   - Run a Streamlit application\n---------------------------------------------------------\nd_n_a   - Download a NTSB MS Access database file\nl_n_a   - Load NTSB MS Access database data into PostgreSQL\nc_l_l   - Correct decimal US latitudes and longitudes\nv_n_d   - Verify selected NTSB data\nr_d_s   - Refresh the PostgreSQL database schema\n---------------------------------------------------------\nc_p_d   - Cleansing PostgreSQL data\nl_c_d   - Load data from a correction file into PostgreSQL\nl_c_s   - Load country and state data into PostgreSQL\nl_s_d   - Load simplemaps data into PostgreSQL\nl_z_d   - Load ZIP Code Database data into PostgreSQL\n---------------------------------------------------------\nc_d_s   - Create the PostgreSQL database schema\nu_d_s   - Update the PostgreSQL database schema\n---------------------------------------------------------\nc_d_i   - Create or update a Docker image\nc_d_c   - Run Docker Compose tasks\nc_f_z   - Zip the files for the cloud\n---------------------------------------------------------\nversion - Show the IO-AVSTATS-DB version\n---------------------------------------------------------\nEnter the desired task [default: r_s_a] c_d_i\n=========================================================\nall      - All Streamlit applications\n---------------------------------------------------------\nae1982 - Aircraft Accidents in the US since 1982\npd1982 - Profiling Data for the US since 1982\n---------------------------------------------------------\nEnter the Streamlit application name all\n\nScript run_io_avstats is now running\n=======================================================================\nStart run_io_avstats\n-----------------------------------------------------------------------\nIO-AVSTATS - Aviation Event Statistics.\n-----------------------------------------------------------------------\nPYTHONPATH :\n-----------------------------------------------------------------------\nTASK       : c_d_i\nCORRECTION :\nMSACCESS   :\n-----------------------------------------------------------------------\nThe current time is:  5:26:55.43\nEnter the new time:\n=======================================================================\n\nScript scripts\\run_create_image is now running - Application: all\n\nYou can find the run log in the file run_create_image.log\n\nPlease wait ...\n\n=======================================================================\nStart scripts\\run_create_image\n-----------------------------------------------------------------------\nCreate a Docker image for application all\n-----------------------------------------------------------------------\nDOCKER_CLEAR_CACHE       : yes\nDOCKER_HUB_PUSH          : yes\nSTREAMLIT_SERVER_PORT    : 8501\n-----------------------------------------------------------------------\nThe current time is:  5:26:55.49\nEnter the new time:\n=======================================================================\n\nScript scripts\\run_create_image is now running - Application: ae1982\n\nYou can find the run log in the file run_create_image.log\n\nPlease wait ...\n\n=======================================================================\nStart scripts\\run_create_image\n-----------------------------------------------------------------------\nCreate a Docker image for application ae1982\n-----------------------------------------------------------------------\nDOCKER_CLEAR_CACHE       : yes\nDOCKER_HUB_PUSH          : yes\nSTREAMLIT_SERVER_PORT    : 8501\n-----------------------------------------------------------------------\nThe current time is:  5:26:55.51\nEnter the new time:\n=======================================================================\nDeleted build cache objects:\nuzxx25i0lxo6i63dn7x6m43sf\nk6ij499naa2h1rato1wusqsnb\nybs0ov6x6brbw3mza4ebom3tn\njrl57t6dmkmh16a8cr05eel4v\nmr3hfgjbcvgownt6cgt42hhj8\nv1cew3osiidfg3zjw7oefaxz3\nudbfolcspdf4533lc9km5tlx6\nmpwj560p2a3iao6zvntnb9bmd\najtls8cd4v7c2j0145wpdt62m\nqyva0m4glms5i06qpk50ngydn\n0m34yyo0nfo0njcenkvxgbzuo\ncykj0j5z3dspf7qkltlgiehcx\njhduefpbk7sfzdp3vvw39mcgh\nxee28brnh8940r3yvbt2rvygj\n6b57pxquyoxvqemkpgtwhh0s1\nsvwrr9owakmy9jywyvm3zo0zc\nwjiwh0jvnfkv721221wjbmnjd\nuhf3bsyz66ya2dgg812bxpmj3\n8fq8uoy7bul7us3xbc4y7notj\nodzccrtlsypmao8i86phdqbem\nis2due0y1dwyos9twpcy88qmu\n\nTotal reclaimed space: 2.785GB\nDocker stop/rm ae1982 ................................ before containers:\nCONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                    PORTS                                                      NAMES\n9e010303ef67   postgres:latest          \"docker-entrypoint.s\u2026\"   7 hours ago    Up 24 minutes             0.0.0.0:5432-&gt;5432/tcp                                     io_avstats_db\n2f53ab870011   louislam/uptime-kuma:1   \"/usr/bin/dumb-init \u2026\"   6 days ago     Up 24 minutes (healthy)   0.0.0.0:3001-&gt;3001/tcp                                     uptime-kuma\nf67eb28b8888   portainer/portainer-ce   \"/portainer\"             2 months ago   Up 24 minutes             0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp, 9443/tcp   portainer\n............................................................. after containers:\nCONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                    PORTS                                                      NAMES\n9e010303ef67   postgres:latest          \"docker-entrypoint.s\u2026\"   7 hours ago    Up 24 minutes             0.0.0.0:5432-&gt;5432/tcp                                     io_avstats_db\n2f53ab870011   louislam/uptime-kuma:1   \"/usr/bin/dumb-init \u2026\"   6 days ago     Up 24 minutes (healthy)   0.0.0.0:3001-&gt;3001/tcp                                     uptime-kuma\nf67eb28b8888   portainer/portainer-ce   \"/portainer\"             2 months ago   Up 24 minutes             0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp, 9443/tcp   portainer\n............................................................. before images:\nREPOSITORY               TAG       IMAGE ID       CREATED        SIZE\nioaero/pd1982          latest    21178cc3b8bc   36 hours ago   3.71GB\nioaero/ae1982          latest    55595e574018   36 hours ago   3.71GB\nlouislam/uptime-kuma     1         7a23beca3798   7 days ago     382MB\npostgres                 latest    a26eb6069868   11 days ago    379MB\nlouislam/uptime-kuma     &lt;none&gt;    930a7e08142f   2 months ago   350MB\nportainer/portainer-ce   latest    500504ac663a   3 months ago   285MB\nioaero/ae1982          latest    55595e574018   36 hours ago   3.71GB\nUntagged: ioaero/ae1982:latest\nUntagged: ioaero/ae1982@sha256:8e0508754352cf9fbfd5c1957df825aab5703d8ec7ed85d6c44358f0bc701e2d\nDeleted: sha256:55595e574018ea4759bb7a13e51aaea8e869fe84e49c17ff05f5234b0b65f6b0\nDeleted: sha256:119fc70cf352a239f7e323ba1d9b7603fb77e899ca0db5b4bc994b577cb55f45\nDeleted: sha256:8922e3751ae2b60d598394358173719c4043d29ae71e8d709a305a5432f70f36\nDeleted: sha256:6a95257bdb25543436f2741138e8e4cdee6121409b665f51d2f2fdcb3228a8bc\nDeleted: sha256:7c6422e12c7c23e441493c9177661519dd616a418c7cd9ea6c3acfab981b5279\nDeleted: sha256:3539296c13a8b190f45a4d7d66330d3396e5b1d5e81200ae492b0a0b1fe8b914\nDeleted: sha256:06758fe39d1e7343a30e0f4d62d57abd997164a4840c6af6136953f12953f81d\nDeleted: sha256:6a2295de770bec3782f572ee92533e5c120dda4a7a8f07faea3fe21a8fa5b9d2\nDeleted: sha256:82fa1f4f9b491d32fa8f2fda71e7c8223f2ea66d85b92b19869554e4342f2a55\n............................................................. after images:\nREPOSITORY               TAG       IMAGE ID       CREATED        SIZE\nioaero/pd1982          latest    21178cc3b8bc   36 hours ago   3.71GB\nlouislam/uptime-kuma     1         7a23beca3798   7 days ago     382MB\npostgres                 latest    a26eb6069868   11 days ago    379MB\nlouislam/uptime-kuma     &lt;none&gt;    930a7e08142f   2 months ago   350MB\nportainer/portainer-ce   latest    500504ac663a   3 months ago   285MB\n[+] Building 126.0s (16/16) FINISHED\n =&gt; [internal] load build definition from Dockerfile                                                                                                                                  0.1s\n =&gt; =&gt; transferring dockerfile: 685B                                                                                                                                                  0.0s\n =&gt; [internal] load .dockerignore                                                                                                                                                     0.1s\n =&gt; =&gt; transferring context: 2B                                                                                                                                                       0.0s\n =&gt; [internal] load metadata for docker.io/library/python:3.10.9                                                                                                                      1.6s\n =&gt; [auth] library/python:pull token for registry-1.docker.io                                                                                                                         0.0s\n =&gt; [internal] load build context                                                                                                                                                     0.1s\n =&gt; =&gt; transferring context: 54.51kB                                                                                                                                                  0.0s\n =&gt; [ 1/10] FROM docker.io/library/python:3.10.9@sha256:e18f86de2e5eadcb00af7d57eefeeb377aec81a41d033bf20de426ae6c7bbff6                                                              0.3s\n =&gt; =&gt; resolve docker.io/library/python:3.10.9@sha256:e18f86de2e5eadcb00af7d57eefeeb377aec81a41d033bf20de426ae6c7bbff6                                                                0.0s\n =&gt; =&gt; sha256:e18f86de2e5eadcb00af7d57eefeeb377aec81a41d033bf20de426ae6c7bbff6 2.36kB / 2.36kB                                                                                        0.0s\n =&gt; =&gt; sha256:3aae3bded9cfb06e92d7342abf1833b156fe197522ffbde031363194c429c8d5 8.53kB / 8.53kB                                                                                        0.0s\n =&gt; =&gt; sha256:08dfb526b02f1b849ca4ce479b51f100448053a67b64905a63dcdad2fe6802c5 2.22kB / 2.22kB                                                                                        0.0s\n =&gt; [ 2/10] WORKDIR /home                                                                                                                                                             0.0s\n =&gt; [ 3/10] COPY .settings.io_avstats.toml ./                                                                                                                                         0.0s\n =&gt; [ 4/10] COPY .streamlit/config.toml ./.streamlit/                                                                                                                                 0.0s\n =&gt; [ 5/10] COPY .streamlit/secrets_4_dockerfile.toml ./.streamlit/secrets.toml                                                                                                       0.0s\n =&gt; [ 6/10] COPY Makefile ./                                                                                                                                                          0.0s\n =&gt; [ 7/10] COPY Pipfile ./                                                                                                                                                           0.0s\n =&gt; [ 8/10] COPY settings.io_avstats_4_dockerfile.toml ./settings.io_avstats.toml                                                                                                     0.0s\n =&gt; [ 9/10] COPY src/streamlit_apps/ae1982.py ./ae1982.py                                                                                                                         0.0s\n =&gt; [10/10] RUN make pipenv-prod                                                                                                                                                    116.1s\n =&gt; exporting to image                                                                                                                                                                7.6s\n =&gt; =&gt; exporting layers                                                                                                                                                               7.6s\n =&gt; =&gt; writing image sha256:9c52d19f49cab5d423d3829c9bf9a275646a6c8102664798439d2f6a8a36ec70                                                                                          0.0s\n =&gt; =&gt; naming to docker.io/ioaero/ae1982                                                                                                                                            0.0s\nUsing default tag: latest\nThe push refers to repository [docker.io/ioaero/ae1982]\ne0d3af52dd2a: Pushed\n02cd2263f756: Pushed\n4303b7702627: Pushed\n09bdea621e5d: Pushed\n4fa461cf256d: Pushed\n36b2ed23b0c8: Pushed\nbf522582bcc8: Pushed\n568d53719d94: Pushed\n5f70bf18a086: Layer already exists\n6cda7fb97c48: Layer already exists\na5ea5c85f053: Layer already exists\n86ee53f76eff: Layer already exists\n248397b6b856: Layer already exists\nfa1175420e6f: Layer already exists\nbb2453e12947: Layer already exists\n7354e83da007: Layer already exists\nc284f546974c: Layer already exists\n4efcd4003c84: Layer already exists\nlatest: digest: sha256:7a10f6e705635ba099fc1e7751ce8ba7e8ab42a3effd1c85e5e391e87b3d7713 size: 4090\n-----------------------------------------------------------------------\nThe current time is:  5:29:48.32\nEnter the new time:\n-----------------------------------------------------------------------\nEnd   scripts\\run_create_image\n=======================================================================\n\nScript scripts\\run_create_image is now running - Application: pd1982\n\nYou can find the run log in the file run_create_image.log\n\nPlease wait ...\n\n=======================================================================\nStart scripts\\run_create_image\n-----------------------------------------------------------------------\nCreate a Docker image for application pd1982\n-----------------------------------------------------------------------\nDOCKER_CLEAR_CACHE       : yes\nDOCKER_HUB_PUSH          : yes\nSTREAMLIT_SERVER_PORT    : 8501\n-----------------------------------------------------------------------\nThe current time is:  5:29:48.34\nEnter the new time:\n=======================================================================\nDeleted build cache objects:\nthhicfsjzega5hhfsfhgazo5f\nc0hrwt7xm4gqwku594jwovtxy\nmj3v2y03lne206mx98ck6bs5q\nt91qc536n2yxg4khxtg8ujpy7\nmxil38rm6bwdx496jkxz7mlao\nd8yhfp8fu7c8pyswiomy19unw\nypkmd6a84ytbkimlxvc5hge2r\ntbn52lkr2rwt8kgl4taocwdq9\n0hhmtdy5632ayhrwjbknd6wmu\nv9nu6ong6kpge0wgy5hw7msd0\n5wab3qctjhthudw31strfmcas\ncvx5a4vxg4wl96bm66r65c3im\n05e4dt4o8ts5myzatdapc3zbp\nrei1avwchsi7rcwwwxyqj5bek\nuuz6tgeqx4aakkd5rk6mviwqw\nkuiq5mq3o4fdr7t1fjh59kf3z\nsz0a79o1lfbfjoffp2xad68d9\np5srd861jgkz1jim3hlagwy5k\nk9hr87wufmsxkrcn95mvzncx9\nd0y2kal9jkigo3d1iwmnv6c5x\ncop4h1ejwr20j5i6ilnjm2udh\n\nTotal reclaimed space: 2.787GB\nDocker stop/rm pd1982 ................................ before containers:\nCONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                          PORTS                                                      NAMES\n9e010303ef67   postgres:latest          \"docker-entrypoint.s\u2026\"   7 hours ago    Exited (0) About a minute ago                                                              io_avstats_db\n2f53ab870011   louislam/uptime-kuma:1   \"/usr/bin/dumb-init \u2026\"   6 days ago     Up 27 minutes (healthy)         0.0.0.0:3001-&gt;3001/tcp                                     uptime-kuma\nf67eb28b8888   portainer/portainer-ce   \"/portainer\"             2 months ago   Up 27 minutes                   0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp, 9443/tcp   portainer\n............................................................. after containers:\nCONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                          PORTS                                                      NAMES\n9e010303ef67   postgres:latest          \"docker-entrypoint.s\u2026\"   7 hours ago    Exited (0) About a minute ago                                                              io_avstats_db\n2f53ab870011   louislam/uptime-kuma:1   \"/usr/bin/dumb-init \u2026\"   6 days ago     Up 27 minutes (healthy)         0.0.0.0:3001-&gt;3001/tcp                                     uptime-kuma\nf67eb28b8888   portainer/portainer-ce   \"/portainer\"             2 months ago   Up 27 minutes                   0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp, 9443/tcp   portainer\n............................................................. before images:\nREPOSITORY               TAG       IMAGE ID       CREATED          SIZE\nioaero/ae1982          latest    9c52d19f49ca   53 seconds ago   3.71GB\nioaero/pd1982          latest    21178cc3b8bc   36 hours ago     3.71GB\nlouislam/uptime-kuma     1         7a23beca3798   7 days ago       382MB\npostgres                 latest    a26eb6069868   11 days ago      379MB\nlouislam/uptime-kuma     &lt;none&gt;    930a7e08142f   2 months ago     350MB\nportainer/portainer-ce   latest    500504ac663a   3 months ago     285MB\nioaero/pd1982          latest    21178cc3b8bc   36 hours ago     3.71GB\nUntagged: ioaero/pd1982:latest\nUntagged: ioaero/pd1982@sha256:81275d3926397906a73a897d067081b957a94c944c01fede413eb998916abdb3\nDeleted: sha256:21178cc3b8bc68774299f0015c9aff0ff819078d62174db6e13da31fe8253ece\nDeleted: sha256:b0403dd2d4728d6cdb151bdd2e182b3170de1b0cbf5f0b7e00c17dddcc389f5b\nDeleted: sha256:10742399ddf223a435aaf2674a553baf3c5a1345aad7d6a4f5dabe4a4398ad25\nDeleted: sha256:154ad29ff275517ad1f803aa1efc0bb372ea9f37d7f0273b432ae1dfa8af87c2\nDeleted: sha256:2ffd78873dbaec78fbcf969f45396338bdb809f38c04a41862f74c4d18ded62e\nDeleted: sha256:faf980ada2cc0547773a54a6a55bae285088dd9afb7f29a0f1f36a6230f406c9\nDeleted: sha256:9bbb505d8de414f3da1416a76cd56e6e8144e35652bf06b9b2f389d5ade00aea\nDeleted: sha256:ccd5b1ddd9e1cfb8897f307f303097fafd12e1cf3220603419c03a4394138653\nDeleted: sha256:2be71d95e8f20b84ab51375e52afc7665926a2ac52e22b32b82bb8f374082d13\n............................................................. after images:\nREPOSITORY               TAG       IMAGE ID       CREATED          SIZE\nioaero/ae1982          latest    9c52d19f49ca   54 seconds ago   3.71GB\nlouislam/uptime-kuma     1         7a23beca3798   7 days ago       382MB\npostgres                 latest    a26eb6069868   11 days ago      379MB\nlouislam/uptime-kuma     &lt;none&gt;    930a7e08142f   2 months ago     350MB\nportainer/portainer-ce   latest    500504ac663a   3 months ago     285MB\n[+] Building 125.4s (15/15) FINISHED\n =&gt; [internal] load build definition from Dockerfile                                                                                                                                  0.0s\n =&gt; =&gt; transferring dockerfile: 685B                                                                                                                                                  0.0s\n =&gt; [internal] load .dockerignore                                                                                                                                                     0.0s\n =&gt; =&gt; transferring context: 2B                                                                                                                                                       0.0s\n =&gt; [internal] load metadata for docker.io/library/python:3.10.9                                                                                                                      1.0s\n =&gt; [ 1/10] FROM docker.io/library/python:3.10.9@sha256:e18f86de2e5eadcb00af7d57eefeeb377aec81a41d033bf20de426ae6c7bbff6                                                              0.4s\n =&gt; =&gt; resolve docker.io/library/python:3.10.9@sha256:e18f86de2e5eadcb00af7d57eefeeb377aec81a41d033bf20de426ae6c7bbff6                                                                0.0s\n =&gt; =&gt; sha256:e18f86de2e5eadcb00af7d57eefeeb377aec81a41d033bf20de426ae6c7bbff6 2.36kB / 2.36kB                                                                                        0.0s\n =&gt; =&gt; sha256:08dfb526b02f1b849ca4ce479b51f100448053a67b64905a63dcdad2fe6802c5 2.22kB / 2.22kB                                                                                        0.0s\n =&gt; =&gt; sha256:3aae3bded9cfb06e92d7342abf1833b156fe197522ffbde031363194c429c8d5 8.53kB / 8.53kB                                                                                        0.0s\n =&gt; [internal] load build context                                                                                                                                                     0.0s\n =&gt; =&gt; transferring context: 43.50kB                                                                                                                                                  0.0s\n =&gt; [ 2/10] WORKDIR /home                                                                                                                                                             0.0s\n =&gt; [ 3/10] COPY .settings.io_avstats.toml ./                                                                                                                                         0.1s\n =&gt; [ 4/10] COPY .streamlit/config.toml ./.streamlit/                                                                                                                                 0.0s\n =&gt; [ 5/10] COPY .streamlit/secrets_4_dockerfile.toml ./.streamlit/secrets.toml                                                                                                       0.0s\n =&gt; [ 6/10] COPY Makefile ./                                                                                                                                                          0.0s\n =&gt; [ 7/10] COPY Pipfile ./                                                                                                                                                           0.0s\n =&gt; [ 8/10] COPY settings.io_avstats_4_dockerfile.toml ./settings.io_avstats.toml                                                                                                     0.1s\n =&gt; [ 9/10] COPY src/streamlit_apps/pd1982.py ./pd1982.py                                                                                                                         0.0s\n =&gt; [10/10] RUN make pipenv-prod                                                                                                                                                    116.0s\n =&gt; exporting to image                                                                                                                                                                7.6s\n =&gt; =&gt; exporting layers                                                                                                                                                               7.6s\n =&gt; =&gt; writing image sha256:352591832f346b0b30d89f33e01572eb1710024841c0d6fecd53a74b22ca5c09                                                                                          0.0s\n =&gt; =&gt; naming to docker.io/ioaero/pd1982                                                                                                                                            0.0s\nUsing default tag: latest\nThe push refers to repository [docker.io/ioaero/pd1982]\nfcd1849b77ee: Pushed\n9b8fc3075985: Pushed\n23c8d1891816: Pushed\nadebe552f5a4: Pushed\n1dddc5e9e66a: Pushed\nad5de2585a3a: Pushed\nbf4ee8dfaa14: Pushed\n3e99a612e0bf: Pushed\n5f70bf18a086: Layer already exists\n6cda7fb97c48: Layer already exists\na5ea5c85f053: Layer already exists\n86ee53f76eff: Layer already exists\n248397b6b856: Layer already exists\nfa1175420e6f: Layer already exists\nbb2453e12947: Layer already exists\n7354e83da007: Layer already exists\nc284f546974c: Layer already exists\n4efcd4003c84: Layer already exists\nlatest: digest: sha256:466fe6edd661ee9067d0e77e0fbd1f44acbce0cc6e7f5468dd7e8bf1b6bf05ec size: 4090\n-----------------------------------------------------------------------\nThe current time is:  5:32:40.32\nEnter the new time:\n-----------------------------------------------------------------------\nEnd   scripts\\run_create_image\n=======================================================================\n-----------------------------------------------------------------------\nThe current time is:  5:32:40.33\nEnter the new time:\n-----------------------------------------------------------------------\nEnd   scripts\\run_create_image\n=======================================================================\n\n-----------------------------------------------------------------------\nThe current time is:  5:32:40.34\nEnter the new time:\n-----------------------------------------------------------------------\nEnd   run_io_avstats\n=======================================================================\n</code></pre>"},{"location":"how_to_update_avstats_on_aws.html#2-zip-local-files","title":"2. Zip local files","text":"<p>The script <code>run_io_avstats</code> with task <code>c_f_z</code> zips the required files into the <code>cloud.zip</code> file. The very first thing the script does is stop the PostgreSQL database so that the database files are in a consistent state. Then zip the file directory <code>data/postgres</code> and rename the zipped file <code>postgres.zip</code> to <code>latest_postgres.zip</code>.</p> <p>Example protocol:</p> <pre><code>D:\\SoftDevelopment\\Projects\\IO-Aero\\io-avstats&gt;run_io_avstats\n=========================================================\nr_s_a   - Run a Streamlit application\n---------------------------------------------------------\nd_n_a   - Download a NTSB MS Access database file\nl_n_a   - Load NTSB MS Access database data into PostgreSQL\nc_l_l   - Correct decimal US latitudes and longitudes\nv_n_d   - Verify selected NTSB data\nr_d_s   - Refresh the PostgreSQL database schema\n---------------------------------------------------------\nc_p_d   - Cleansing PostgreSQL data\nl_c_d   - Load data from a correction file into PostgreSQL\nl_c_s   - Load country and state data into PostgreSQL\nl_s_d   - Load simplemaps data into PostgreSQL\nl_z_d   - Load ZIP Code Database data into PostgreSQL\n---------------------------------------------------------\nc_d_s   - Create the PostgreSQL database schema\nu_d_s   - Update the PostgreSQL database schema\n---------------------------------------------------------\nc_d_i   - Create or update a Docker image\nc_d_c   - Run Docker Compose tasks\nc_f_z   - Zip the files for the cloud\n---------------------------------------------------------\nversion - Show the IO-AVSTATS-DB version\n---------------------------------------------------------\nEnter the desired task [default: r_s_a] c_f_z\n\nScript run_io_avstats is now running\n=======================================================================\nStart run_io_avstats\n-----------------------------------------------------------------------\nIO-AVSTATS - Aviation Event Statistics.\n-----------------------------------------------------------------------\nPYTHONPATH :\n-----------------------------------------------------------------------\nTASK       : c_f_z\nCORRECTION :\nMSACCESS   :\n-----------------------------------------------------------------------\nThe current time is:  5:35:14.64\nEnter the new time:\n=======================================================================\n=======================================================================\nStart scripts\\run_cloud_files_zip\n-----------------------------------------------------------------------\nFile Collection for AWS\n-----------------------------------------------------------------------\nThe current time is:  5:35:14.67\nEnter the new time:\n=======================================================================\n\n7-Zip (a) [32] 15.14 : Copyright (c) 1999-2015 Igor Pavlov : 2015-12-31\n\nScanning the drive:\n3 files, 290463129 bytes (278 MiB)\n\nCreating archive: cloud.zip\n\nItems to compress: 3\n\nFiles read from disk: 3\nArchive size: 280942218 bytes (268 MiB)\nEverything is Ok\n\n=======================================================================\nArchive Content\n-----------------------------------------------------------------------\n\n7-Zip (a) [32] 15.14 : Copyright (c) 1999-2015 Igor Pavlov : 2015-12-31\n\nScanning the drive for archives:\n1 file, 280942218 bytes (268 MiB)\n\nListing archive: cloud.zip\n\n--\nPath = cloud.zip\nType = zip\nPhysical Size = 280942218\n\n   Date      Time    Attr         Size   Compressed  Name\n------------------- ----- ------------ ------------  ------------------------\n2023-01-02 23:47:48 ....A    290453357    280940090  data\\latest_postgres.zip\n2022-12-27 01:44:14 ....A         1666          441  docker-compose.yml\n2023-01-01 16:40:06 ....A         8106         1187  scripts\\run_docker_compose.sh\n------------------- ----- ------------ ------------  ------------------------\n2023-01-02 23:47:48          290463129    280941718  3 files\n=======================================================================\n\n-----------------------------------------------------------------------\nThe current time is:  5:35:23.32\nEnter the new time:\n-----------------------------------------------------------------------\nEnd   scripts\\run_cloud_files_zip\n=======================================================================\n\n-----------------------------------------------------------------------\nThe current time is:  5:35:23.33\nEnter the new time:\n-----------------------------------------------------------------------\nEnd   run_io_avstats\n=======================================================================\n</code></pre>"},{"location":"how_to_update_avstats_on_aws.html#3-upload-zip-file","title":"3. Upload zip file","text":"<p>On Windows, the WinSCP program can be used to upload the <code>cloud.zip</code> file from the local system to the AWS Cloud.</p> <p></p> <p></p>"},{"location":"how_to_update_avstats_on_aws.html#4-connect-to-the-aws-instance","title":"4. Connect to the AWS instance","text":""},{"location":"how_to_update_avstats_on_aws.html#5-unzip-in-the-cloud","title":"5. Unzip in the cloud","text":"<p>First, the file <code>cloud.zip</code> is unzipped.</p> <ul> <li><code>unzip cloud.zip</code></li> </ul> <p>Subsequently, the shell script must be made executable:</p> <ul> <li><code>chmod +x scripts/*.sh</code></li> </ul> <p>Afterward                                                                                                                                                                      , a possibly running IO-AVSTATS is terminated.</p> <ul> <li><code>./scripts/run_docker_compose.sh down</code></li> </ul> <p>Next, unzip the database files.</p> <ul> <li><code>cd data</code></li> <li><code>sudo rm -rf postgres</code></li> <li><code>unzip latest_postgres.zip</code></li> </ul> <p>Finally, clean up unnecessary files.</p> <ul> <li><code>rm latest_postgres.zip</code></li> <li><code>cd ..</code></li> <li><code>rm cloud.zip</code></li> </ul>"},{"location":"how_to_update_avstats_on_aws.html#5-restart-io-avstats","title":"5. Restart *IO-AVSTATS","text":"<ul> <li><code>./scripts/run_docker_compose.sh up</code></li> </ul>"},{"location":"how_to_update_avstats_on_aws.html#6-test-the-streamlit-applications","title":"6. Test the Streamlit applications","text":""},{"location":"operation.html","title":"Operation","text":"<p>The main tool for operating IO-AVSTATS is the <code>run_io_avstats</code> script.  The script is available in a Windows command line version and in a Linux bash shell version.</p>"},{"location":"operation.html#1-overview","title":"1. Overview","text":"<p>The following tasks can be executed with this script:</p> Code Task Additional parameter(s) a_o_c Load aviation occurrence categories into PostgreSQL c_d_c Run Docker Compose tasks - Cloud <code>clean</code>, <code>down</code>, <code>logs</code> or <code>up</code> c_d_i Create or update a Docker image <code>all</code> or single Streamlit app c_d_l Run Docker Compose tasks - Local <code>clean</code>, <code>down</code>, <code>logs</code> or <code>up</code> c_d_s Create the PostgreSQL database schema c_f_z Zip the files for the cloud c_l_l Correct decimal US latitudes and longitudes c_p_d Cleansing PostgreSQL data f_n_a Find the nearest airports l_a_p Load airport data into PostgreSQL l_c_d Load data from a correction file into PostgreSQL -e / -excel l_c_s Load country and state data into PostgreSQL l_n_a Load NTSB MS Access database data into PostgreSQL -m / -msaccess l_s_d Load simplemaps data into PostgreSQL l_s_e Load sequence of events data into PostgreSQL l_z_d Load ZIP Code Database data into PostgreSQL r_d_s Refresh the PostgreSQL database schema r_s_a Run a Streamlit application single Streamlit app, e.g. ae1982 u_d_s Update the PostgreSQL database schema u_p_d Complete processing of a modifying MS Access file -m / -msaccess v_n_d Verify selected NTSB data version Show the IO-AVSTATS-DB version"},{"location":"operation.html#2-detailed-task-list","title":"2. Detailed task list","text":""},{"location":"operation.html#21-a_o_c","title":"2.1 <code>a_o_c</code>","text":"<p>Load aviation occurrence categories into PostgreSQL</p>"},{"location":"operation.html#purpose","title":"Purpose","text":"<p>Load the definition of the valid CICTT codes.</p>"},{"location":"operation.html#data-source","title":"Data Source","text":"<p>The data source can be found on the NTSB website here:</p> <ul> <li>AVIATION OCCURRENCE CATEGORIES - DEFINITIONS AND USAGE NOTES</li> </ul> <p>The NTSB provides the data in a <code>pdf</code> file which must then be converted to MS Excel format <code>xlsx</code> before processing.</p>"},{"location":"operation.html#implementation","title":"Implementation","text":"<pre><code>CREATE TABLE public.io_aviation_occurrence_categories (\n    cictt_code varchar(10) NOT NULL,\n    identifier varchar(100) NOT NULL,\n    definition text NOT NULL,\n    first_processed timestamp NOT NULL,\n    last_processed timestamp NULL,\n    last_seen timestamp NULL,\n    CONSTRAINT io_aviation_occurrence_categories_pkey PRIMARY KEY (cictt_code)\n);\n</code></pre>"},{"location":"operation.html#22-c_d_c","title":"2.2 <code>c_d_c</code>","text":"<p>Run Docker Compose tasks - Cloud</p>"},{"location":"operation.html#purpose_1","title":"Purpose","text":"<p>Manage the Docker containers needed in the cloud:</p> <ul> <li>portainer: container management</li> <li>io_avstats_db: PostgreSQL database</li> <li>keycloak_db: PostgreSQL database</li> <li>keycloak: Keycloak server</li> <li>Application ae1982: Aircraft Events since 1982</li> <li>Aoplication members: Members Only Area</li> <li>Application pd1982: Profiling Data since 1982</li> <li>Application slara: Association Rule Analysis</li> <li>Application stats: Aircraft Events since 1982</li> <li>load_balancer: load balancer NGINX</li> </ul>"},{"location":"operation.html#processing-options","title":"Processing Options","text":"<pre><code>- clean - Remove all containers and images\n- down  - Stop  Docker Compose\n- logs  - Fetch the logs of a container\n- up    - Start Docker Compose\n</code></pre>"},{"location":"operation.html#23-c_d_i","title":"2.3 <code>c_d_i</code>","text":"<p>Create or update a Docker image</p>"},{"location":"operation.html#purpose_2","title":"Purpose","text":"<p>Create the application-specific Docker images and store them on DockerHub.  </p>"},{"location":"operation.html#processing-options_1","title":"Processing Options","text":"<pre><code>- all     - All Streamlit applications\n- ae1982  - Aircraft Accidents in the US since 1982\n- members - Members Only Area\n- pd1982  - Profiling Data for the US since 1982\n- slara   - Association Rule Analysis\n- stats   - Aircraft Accidents in the US since 1982 - limited\n</code></pre>"},{"location":"operation.html#24-c_d_l","title":"2.4 <code>c_d_l</code>","text":"<p>Run Docker Compose tasks - Local</p>"},{"location":"operation.html#purpose_3","title":"Purpose","text":"<p>Manage the Docker containers needed locally:</p> <ul> <li>io_avstats_db: PostgreSQL database</li> </ul>"},{"location":"operation.html#processing-options_2","title":"Processing Options","text":"<pre><code>- clean - Remove all containers and images\n- down  - Stop  Docker Compose\n- logs  - Fetch the logs of a container\n- up    - Start Docker Compose\n</code></pre>"},{"location":"operation.html#25-c_d_s","title":"2.5 <code>c_d_s</code>","text":"<p>Create the PostgreSQL database schema</p>"},{"location":"operation.html#purpose_4","title":"Purpose","text":"<p>Create the database schema including the following steps, among others:</p> <ol> <li>creation of a new database user, and</li> <li>creation of a new database, and</li> <li>creation of database objects such as database tables and so on.</li> </ol> <p>The following parameters are used when creating the database schema:</p> <ul> <li><code>postgres_dbname_admin</code> - administration database name</li> <li><code>postgres_password_admin</code> - administration database password</li> <li><code>postgres_user_admin</code> - administration database username</li> </ul> <p>Subsequently, the task <code>u_d_s</code> (Update the PostgreSQL database schema) is also executed.</p> <p>Successful creation of a new database schema requires that neither the user to be created nor the database to be created exists in the PostgreSQL DBMS.</p>"},{"location":"operation.html#26-c_f_z","title":"2.6 <code>c_f_z</code>","text":"<p>Zip the files for the cloud</p>"},{"location":"operation.html#purpose_5","title":"Purpose","text":"<p>Collect and zip the elements needed for the cloud to run the IO-AVSTATS application there. The result is contained in the file cloud.zip.</p>"},{"location":"operation.html#27-c_l_l","title":"2.7 <code>c_l_l</code>","text":"<p>Correct decimal US latitudes and longitudes</p>"},{"location":"operation.html#purpose_6","title":"Purpose","text":"<p>An attempt is made to calculate missing decimal longitudes and latitudes using the database tables <code>io_lat_lng</code> and <code>io_states</code>.</p>"},{"location":"operation.html#implementation_1","title":"Implementation","text":"<ol> <li>In the database table <code>events</code> the values in the columns <code>io_dec_lat_lng_actions</code>, <code>io_dec_latitude</code>, <code>io_dec_longitude</code> and <code>io_latlong_acq</code> are deleted.</li> <li>All rows in the database table <code>events</code> are processed where at least one of the columns <code>dec_latitude</code> or <code>dec_longitude</code> is empty or 0 and the column <code>ev_country</code> has the content <code>USA</code>.</li> </ol> <ul> <li>2.1 An erroneous swapping of latitude and longitude is corrected.</li> <li>2.2 An attempt is made to calculate a missing column <code>dec_latitude</code> from the column <code>latitude</code> and a missing column <code>dec_longitude</code> from the column <code>longitude</code>.</li> <li>2.3 An attempt is made to calculate a missing column <code>dec_latitude</code> or- <code>dec_longitude</code> from the column <code>ev_site_zipcode</code>.</li> <li>2.4 It tries to calculate a missing column <code>dec_latitude</code> or- <code>dec_longitude</code> from the column <code>ev_city</code>.</li> <li>2.5 An attempt is made to calculate a missing column <code>dec_latitude</code> or- <code>dec_longitude</code> from the column <code>ev_state</code>.</li> <li>2.6 For a missing column <code>dec_latitude</code> resp. <code>dec_longitude</code> the center of the USA is assumed.</li> </ul>"},{"location":"operation.html#28-c_p_d","title":"2.8 <code>c_p_d</code>","text":"<p>Cleansing PostgreSQL data</p>"},{"location":"operation.html#purpose_7","title":"Purpose","text":"<p>Clean up data the abnormalities in the database.  This includes the following activities:</p> <ul> <li>remove trailing whitespace in string data types (trimming),</li> <li>converting string data types that contain only whitespace to NULL (nullifying).</li> </ul> <p>As a result, a much simplified processing of the data is possible, e.g. for comparisons.</p> <p>On the one hand, the task can be executed explicitly with the <code>run_io_avstats_db</code> script (task <code>c_p_d</code>) and, on the other hand, it always runs after loading NTSB MS Access data into the PostgreSQL database (task <code>l_n_a</code> and <code>u_p_d</code>).</p>"},{"location":"operation.html#29-f_n_a","title":"2.9 <code>f_n_a</code>","text":"<p>Find the nearest airports</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_8","title":"Purpose","text":""},{"location":"operation.html#210-l_a_p","title":"2.10 <code>l_a_p</code>","text":"<p>Load airport data into PostgreSQL</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_9","title":"Purpose","text":""},{"location":"operation.html#data-source_1","title":"Data Source","text":""},{"location":"operation.html#implementation_2","title":"Implementation","text":""},{"location":"operation.html#211-l_c_d","title":"2.11 <code>l_c_d</code>","text":"<p>Load data from a correction file into PostgreSQL</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_10","title":"Purpose","text":""},{"location":"operation.html#data-source_2","title":"Data Source","text":""},{"location":"operation.html#implementation_3","title":"Implementation","text":"<p>This task allows files containing aviation accident data to be downloaded from the NTSB download site. These files are there as MS Access databases in a compressed format. The following subtasks are executed:</p> <ol> <li>A connection to the NTSB download page is established.</li> <li>The selected file is downloaded to the local system in chunks. </li> <li>The downloaded file is then unpacked. </li> <li>A script with the database schema definition is created with RazorSQL from the downloaded database.</li> <li>The newly created script is then compared with a reference script for matching.</li> </ol>"},{"location":"operation.html#212-l_c_s","title":"2.12 <code>l_c_s</code>","text":"<p>Load country and state data into PostgreSQL</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_11","title":"Purpose","text":""},{"location":"operation.html#data-source_3","title":"Data Source","text":""},{"location":"operation.html#implementation_4","title":"Implementation","text":""},{"location":"operation.html#213-l_n_a","title":"2.13 <code>l_n_a</code>","text":"<p>Load NTSB MS Access database data into PostgreSQL</p>"},{"location":"operation.html#purpose_12","title":"Purpose","text":"<p>This task allows files containing aviation event data to be downloaded from the NTSB download site. These files are there as MS Access databases in a compressed format. The following subtasks are executed:</p> <ol> <li>A connection to the NTSB download page is established.</li> <li>The selected file is downloaded to the local system in chunks. </li> <li>The downloaded file is then unpacked. </li> <li>A script with the database schema definition is created with RazorSQL from the downloaded database.</li> <li>The newly created script is then compared with a reference script for matching.</li> </ol> <p>Subsequently, the downloaded data can be loaded into the PostgreSQL database with the task <code>l_n_a</code> (Load NTSB MS Access database data into PostgreSQL).</p>"},{"location":"operation.html#data-sources","title":"Data Sources","text":"<ul> <li>Pre2008.zip: data set for 1982 through 2007</li> <li>avall.zip: data set from 2008 to the present </li> <li>upDDMON.zip: monthly supplements on the 1st, 8th, 15th and 22nd</li> </ul>"},{"location":"operation.html#implementation_5","title":"Implementation","text":"<p>The PostgreSQL database IO-AVSTATS-DB completely maps the database schema of the NTSB MS Access database.  </p>"},{"location":"operation.html#214-l_s_d","title":"2.14 <code>l_s_d</code>","text":"<p>Load simplemaps data into PostgreSQL</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_13","title":"Purpose","text":""},{"location":"operation.html#data-source_4","title":"Data Source","text":""},{"location":"operation.html#implementation_6","title":"Implementation","text":"<p>This task transfers the data from an NTSB MS Access database previously downloaded from the NTSB website to the PostgreSQL database. The same MS Access database can be processed several times with this task without any problems, since only the changes are newly transferred to the PostgreSQL database. The initial loading is done with both MS Access databases Pre2008 ubd avall. After that only the monthly updates are then transferred. </p>"},{"location":"operation.html#215-l_s_e","title":"2.15 <code>l_s_e</code>","text":"<p>Load sequence of events data into PostgreSQL</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_14","title":"Purpose","text":""},{"location":"operation.html#data-source_5","title":"Data Source","text":""},{"location":"operation.html#implementation_7","title":"Implementation","text":""},{"location":"operation.html#216-l_z_d","title":"2.16 <code>l_z_d</code>","text":"<p>Load ZIP Code Database data into PostgreSQL</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#purpose_15","title":"Purpose","text":""},{"location":"operation.html#data-source_6","title":"Data Source","text":""},{"location":"operation.html#implementation_8","title":"Implementation","text":"<p>This task transfers the data from an NTSB MS Access database previously downloaded from the NTSB website to the PostgreSQL database. The same MS Access database can be processed several times with this task without any problems, since only the changes are newly transferred to the PostgreSQL database. The initial loading is done with both MS Access databases Pre2008 ubd avall. After that only the monthly updates are then transferred. </p>"},{"location":"operation.html#217-r_d_s","title":"2.17 <code>r_d_s</code>","text":"<p>Refresh the PostgreSQL database schema</p> <ul> <li>TODO</li> </ul> <p>Hereby changes can be made to the database schema. The task can be executed several times without problems, since before a change is always first checked whether this has already been done.</p> <ol> <li> <p>Materialized database view</p> </li> <li> <p><code>io_app_ae1982</code> - provides the data for processing the task <code>c_l_l</code> (Correct decimal US latitudes and longitudes).</p> </li> </ol> <p>Example protocol:</p> <pre><code>Progress update 2022-12-19 08:37:09.337180 : INFO.00.004 Start Launcher.\nProgress update 2022-12-19 08:37:09.342679 : INFO.00.001 The logger is configured and ready.\nProgress update 2022-12-19 08:37:09.352180 : INFO.00.005 Argument task='r_d_s'.\nProgress update 2022-12-19 08:37:09.352180 : -------------------------------------------------------------------------------.\nProgress update 2022-12-19 08:37:09.352180 : INFO.00.071 Refreshing the database schema.\nProgress update 2022-12-19 08:37:09.352180 : --------------------------------------------------------------------------------\nProgress update 2022-12-19 08:37:19.366370 : INFO.00.069 Materialized database view is refreshed: io_app_ae1982.\nProgress update 2022-12-19 08:37:19.366370 : -------------------------------------------------------------------------------.\nProgress update 2022-12-19 08:37:19.366370 :       10,187,690,800 ns - Total time launcher.\nProgress update 2022-12-19 08:37:19.366370 : INFO.00.006 End   Launcher.\nProgress update 2022-12-19 08:37:19.366370 : ===============================================================================.\n</code></pre>"},{"location":"operation.html#218-r_s_a","title":"2.18 <code>r_s_a</code>","text":"<p>Run a Streamlit application</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#219-u_d_s","title":"2.19 <code>u_d_s</code>","text":"<p>Update the PostgreSQL database schema</p> <ul> <li>TODO</li> </ul> <p>Hereby changes can be made to the database schema. The task can be executed several times without problems, since before a change is always first checked whether this has already been done.</p> <ol> <li> <p>New database tables:</p> </li> <li> <p><code>io_countries</code>: contains latitude and longitude of selected countries.</p> </li> <li><code>io_lat_lng</code>: used to store the simplemaps and United States Zip Codes.org data.</li> <li> <p><code>io_states</code>: contains the identification, name, latitude and longitude of all US states.</p> </li> <li> <p>Extensions for database tables:</p> </li> </ol> <p>2.1 Database table <code>events</code>.</p> <ul> <li>The columns <code>io_city</code>, <code>io_country</code>, <code>io_latitude</code>, <code>io_longitude</code>, <code>io_site_zipcode</code> and <code>io_state</code> to store manual corrections.</li> <li>The columns <code>io_deviating_dec_latitude</code>, <code>io_deviating_dec_longitude</code>, <code>io_invalid_latitude</code>, <code>io_invalid_longitude</code>, <code>io_invalid_us_city</code>, <code>io_invalid_us_state</code> and , <code>io_invalid_us_zipcode</code> for documenting data plausibility (task <code>v_n_d</code>).</li> <li> <p>the columns <code>io_dec_lat_lng_actions</code>, <code>io_dec_latitude</code> and <code>io_dec_longitude</code> to store corrected decimal latitude and longitude values.</p> </li> <li> <p>New database views:</p> </li> <li> <p><code>io_lat_lng_issues</code> - provides the data for processing the task <code>c_l_l</code> (Correct decimal US latitudes and longitudes).</p> </li> <li><code>io_accidents_us_1982</code> - provides event data for aviation accidents in the U.S. since 1982.</li> </ul>"},{"location":"operation.html#220-u_p_d","title":"2.20 <code>u_p_d</code>","text":"<p>Complete processing of a modifying MS Access file</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#221-v_n_d","title":"2.21 <code>v_n_d</code>","text":"<p>Verify selected NTSB data</p> <ul> <li>TODO</li> </ul> <p>This task can be used to perform a plausibility check for the following columns in the database table <code>events</code>:</p> <ul> <li><code>dec_latitude</code>,</li> <li><code>dec_longitude</code>,</li> <li><code>ev_state</code>,</li> <li><code>ev_site_zipcode</code>,</li> <li><code>latitude</code>,</li> <li><code>longitude</code>,</li> </ul> <p>and the combination of:</p> <ul> <li><code>ev_state</code> and <code>ev_city</code>,</li> <li><code>ev_state</code>, <code>ev_city</code> and <code>ev_site_zipcode</code>.</li> </ul> <p>The results of the check are stored in the following columns:</p> <ul> <li><code>io_deviating_dec_latitude</code> (absolute difference),</li> <li><code>io_deviating_dec_longitude</code> (absolute difference),</li> <li><code>io_invalid_latitude</code> (true),</li> <li><code>io_invalid_longitude</code> (true),</li> <li><code>io_invalid_us_city</code> (true),</li> <li><code>io_invalid_us_city_zipcode</code> (true),</li> <li><code>io_invalid_us_state</code> (true),</li> <li><code>io_invalid_us_zipcode</code> (true).</li> </ul> <p>The tests are performed according to the following logic:</p> <ul> <li><code>io_deviating_dec_latitude</code>: Absolute difference between <code>dec_latitude</code> and <code>latitude</code> exceeding a given limit in <code>max_deviation_latitude</code>.</li> <li><code>io_deviating_dec_longitude</code>: Absolute difference between <code>dec_longitude</code> and <code>longitude</code> exceeding a given limit <code>max_deviation_longitude</code>.</li> <li><code>io_invalid_latitude</code>: Can the latitude in the <code>latitude</code> column be converted to its decimal equivalent?</li> <li><code>io_invalid_longitude</code>: Can the longitude in the <code>longitude</code> column be converted to its decimal equivalent?</li> <li><code>io_invalid_us_city</code>: For country <code>USA</code> and the given state, is the specified value in the <code>ev_city</code> column a existing city?</li> <li><code>io_invalid_us_city_zipcode</code>: For country <code>USA</code> and the given state, are the specified values in the <code>ev_city</code> column and in the <code>ev_site_zipcode</code> column a existing city?</li> <li><code>io_invalid_us_state</code>: For country <code>USA</code>, is the specified value in the <code>ev_state</code> column a valid state identifier?</li> <li><code>io_invalid_us_z ipcode</code>: For country <code>USA</code>, is the specified value in the <code>ev_site_zipcode</code> column a existing zip code?</li> </ul>"},{"location":"operation.html#222-version","title":"2.22 <code>version</code>","text":"<p>Show the IO-AVSTATS-DB version</p> <ul> <li>TODO</li> </ul>"},{"location":"operation.html#3-first-installation","title":"3. First installation","text":"<p>The initial load in a fresh Windows environment requires the execution of the following tasks in the given order:</p> <ul> <li><code>c_d_l</code> - Run Docker Compose tasks - Local                              </li> <li><code>c_d_s</code> - Create the PostgreSQL database schema </li> </ul> <ul> <li><code>l_c_s</code> - Load country and state data into PostgreSQL</li> <li><code>l_a_p</code> - Load airport data into PostgreSQL</li> <li><code>a_o_c</code> - Load aviation occurrence categories into PostgreSQL</li> <li><code>l_s_e</code> - Load sequence of events data into PostgreSQL</li> <li><code>l_s_d</code> - Load simplemaps data into PostgreSQL</li> <li><code>l_z_d</code> - Load ZIP Code Database data into PostgreSQL</li> </ul> <ul> <li><code>u_p_d</code> - Complete processing of a modifying MS Access file: <code>Pre2008</code></li> </ul>"},{"location":"operation.html#4-regular-updates","title":"4. Regular updates","text":""},{"location":"operation.html#41-every-1st-of-the-month","title":"4.1 Every 1st of the month","text":"<ol> <li>Stop the Docker container <code>io_avstats_db</code></li> <li>Restore the current state of Pre2008</li> <li>Start the Docker container <code>io_avstats_db</code></li> <li>Process the current <code>avall</code> file with code <code>l_n_a</code></li> <li>Process the current <code>up01MON</code> file with code <code>u_p_d</code></li> </ol>"},{"location":"operation.html#42-every-8th-15th-and-22nd","title":"4.2 Every 8th, 15th and 22nd","text":"<ul> <li>Process the current <code>upDDMON</code> file with code <code>u_p_d</code></li> </ul>"},{"location":"release_schedule.html","title":"Release Schedule","text":"<p>To create a new release, the following steps must be performed in the specified order. It is not allowed to continue with the next step until the current step has been completed successfully, i.e. also without any errors. </p>"},{"location":"release_schedule.html#1-manual-quality-control","title":"1. Manual quality control.","text":""},{"location":"release_schedule.html#a-remove-all-personal-markers","title":"a) Remove all personal markers.","text":"<p>It is good practice to mark experimental source code, such as source code comments or logging messages that are only used for testing, with a uniform personal marker, such as <code>lho</code> or <code>wwe</code>, so that this source code can be easily discovered and removed for release builds.</p>"},{"location":"release_schedule.html#b-check-all-todo-markers-for-necessity","title":"b) Check all <code>TODO</code> markers for necessity.","text":""},{"location":"release_schedule.html#c-check-all-links-in-the-docs-file-directory","title":"c) Check all links in the <code>docs</code> file directory.","text":"<p>Links should generally contain the following suffix: <code>{:target=\"_blank\"}</code>.  This ensures that a web page activated by the link is opened in a new tab.</p>"},{"location":"release_schedule.html#d-unnecessary-annotations-pytestmarkissue-in-the-file-directory-tests","title":"d) Unnecessary annotations <code>@pytest.mark.issue</code> in the file directory <code>tests</code>.","text":"<p>This annotation can be used to run individual tests selectively.  To remove the remains of it one can use the regular expression <code>^@pytest.mark.issue</code>.</p>"},{"location":"release_schedule.html#2-define-a-new-version-number","title":"2. Define a new version number.","text":"<p>The rules of semantic versioning must be applied.  Given a version number MAJOR.MINOR.PATCH, increment the:</p> <ul> <li>MAJOR version when you make incompatible API changes</li> <li>MINOR version when you add functionality in a backwards compatible manner</li> <li>PATCH version when you make backwards compatible bug fixes</li> </ul> <p>See here for details.</p>"},{"location":"release_schedule.html#a-update-the-version-number-in-the-io-avstats-files","title":"a) Update the version number in the IO-AVSTATS files:","text":"<ul> <li>docs/release_history.md</li> <li>docs/release_notes.md</li> <li>src//io_glob.py</li> </ul>"},{"location":"release_schedule.html#3-create-release-candidate-branch-rel_branch","title":"3. Create release candidate branch <code>&lt;rel_branch&gt;</code>.","text":""},{"location":"release_schedule.html#4-switch-to-the-release-candidate-branch-rel_branch","title":"4. Switch to the release candidate branch <code>&lt;rel_branch&gt;</code>.","text":"<pre><code>git checkout &lt;rel_branch&gt;\n</code></pre>"},{"location":"release_schedule.html#5-finalise-the-new-release","title":"5. Finalise the new release.","text":""},{"location":"release_schedule.html#a-execute-the-following-command-in-the-io-avstats-clone","title":"a. Execute the following command in the IO-AVSTATS clone.","text":"<pre><code>make final\n</code></pre>"},{"location":"release_schedule.html#b-create-the-final-pull-request","title":"b. Create the final pull request.","text":""},{"location":"release_schedule.html#c-create-the-new-release-in-github","title":"c. Create the new release in GitHub:","text":"<ul> <li>Releases --&gt; Create a new release</li> <li>Choose a tag ---&gt; <code>9.9.9</code> ---&gt; + Create a new tag</li> <li>Release title ---&gt; <code>Release 9.9.9: &lt;headline&gt;</code>.</li> <li>Describe the release ---&gt; <code>see: https://github.com/io-aero/io-avstats/blob/main/docs/release_notes.md</code></li> <li><code>x</code> This is a pre-release</li> <li><code>x</code> Create a discussion for this release</li> <li>Publish release</li> </ul>"},{"location":"release_schedule.html#6-preepare-the-next-release","title":"6. Preepare the next release.","text":""},{"location":"release_schedule.html#a-choose-a-new-version-number","title":"a. Choose a new version number.","text":""},{"location":"release_schedule.html#b-prepare-the-following-files-in-the-io-rsaster-repository-for-the-new-version","title":"b. Prepare the following files in the io-rsaster repository for the new version:","text":"<ul> <li>docs/release_history.md</li> <li>docs/release_notes.md</li> <li>src//io_glob.py</li> </ul>"},{"location":"setup_installation.html","title":"Installation","text":"<ol> <li> <p>Clone or copy the IO-AVSTATS repository from here.</p> </li> <li> <p>Switch to the file directory io-avstats:</p> <p><code>cd io-avstats</code></p> </li> <li> <p>Install the necessary Python packages by running the command  <code>make pipenv-dev</code>.</p> </li> <li> <p>Optionally, adjustments can be made in the following configuration files:</p> <ul> <li><code>logging_cfg.yaml</code>: for the logging functionality</li> <li><code>settings.io_avstats.toml</code>: for the IO-AVSTATS application</li> </ul> </li> <li> <p>Create the configuration file <code>.settings.io_avstats.toml</code> with the passwords for the PostgreSQL database users.</p> </li> <li> <p>Use the IO-AVSTATS application by running the script <code>run_io_avstats.bat</code>.</p> </li> </ol>"},{"location":"setup_requirements.html","title":"Requirements","text":"<p>The following are the minimum requirements to run the application:</p> <ul> <li>Operating System <code>Windows 10</code> or <code>Windows 11</code> - except for the tasks that require ODBC, the operating system <code>Ubuntu LTS 20.04</code> can also be used.</li> </ul> <ul> <li>Docker Desktop </li> <li>The LLVM Compiler Infrastructure </li> <li>Make for Windows </li> <li>MS Access Database Engine 2016 Redistributable</li> <li>PostgreSQL - only \"Command Line Tools\"</li> <li>Python</li> <li>RazorSQL</li> <li>Visual Studio Community 2022</li> </ul>"},{"location":"img/index.html","title":"File Directory <code>docs/img</code>","text":"<p>This directory contains all the image files used in the documentation. </p>"}]}